{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test dataset's Saved value on Ranknet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class RankNetDataset(Dataset):\n",
    "    def __init__(self, df, features):\n",
    "        self.features = df[features].values\n",
    "        self.labels = df['Saved'].values\n",
    "        self.response_ids = df['ResponseID'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        response_id = self.response_ids[idx]\n",
    "        return features, labels, response_id\n",
    "\n",
    "class RankNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RankNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class RankNetModel:\n",
    "    def __init__(self, features, model_path='ranknet_model.pth'):\n",
    "        self.features = features\n",
    "        self.model_path = model_path\n",
    "        self.model = RankNet(len(features))\n",
    "\n",
    "    def train(self, train_df, val_df, batch_size=32, epochs=50, patience=5, learning_rate=0.0005):\n",
    "        train_dataset = RankNetDataset(train_df, self.features)\n",
    "        val_dataset = RankNetDataset(val_df, self.features)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            for features, labels, _ in train_loader:\n",
    "                labels = labels.view(-1, 1)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss / len(train_loader):.4f}\")\n",
    "\n",
    "            self.model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for features, labels, _ in val_loader:\n",
    "                    labels = labels.view(-1, 1)\n",
    "                    outputs = self.model(features)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "            val_loss /= len(val_loader)\n",
    "            print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(self.model.state_dict(), self.model_path)\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model.load_state_dict(torch.load(self.model_path))\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, test_df, batch_size=32):\n",
    "        test_dataset = RankNetDataset(test_df, self.features)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for features, labels, response_ids in test_loader:\n",
    "                outputs = torch.sigmoid(self.model(features)).view(-1)\n",
    "                for i in range(len(response_ids)):\n",
    "                    predictions.append((response_ids[i], outputs[i].item(), labels[i].item()))\n",
    "\n",
    "        predictions_df = pd.DataFrame(predictions, columns=['ResponseID', 'Predicted Probability', 'True Label'])\n",
    "\n",
    "        # Update the logic to group by ResponseID and assign Predicted Saved\n",
    "        final_predictions = []\n",
    "        for response_id, group in predictions_df.groupby('ResponseID'):\n",
    "            group = group.sort_values(by='Predicted Probability', ascending=False)\n",
    "            group['Predicted Saved'] = [1 if idx == 0 else 0 for idx in range(len(group))]\n",
    "            final_predictions.append(group)\n",
    "\n",
    "        return pd.concat(final_predictions)\n",
    "\n",
    "    def evaluate(self, predictions_df):\n",
    "        y_true = predictions_df['True Label']\n",
    "        y_pred = predictions_df['Predicted Saved']\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        roc_auc = roc_auc_score(y_true, predictions_df['Predicted Probability'])\n",
    "\n",
    "        print(f\"\\nModel Performance Metrics:\\nAccuracy: {accuracy:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\\nF1 Score: {f1:.4f}\\nROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Saved', 'Saved'], yticklabels=['Not Saved', 'Saved'])\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('1230_tets.csv')\n",
    "tt = ['if_more_vulnerable', 'if_more_children', 'if_more_senior',\n",
    "       'if_more_criminal', 'if_more_homeless', 'if_more_profession',\n",
    "       'if_more_large', 'if_more_animal']\n",
    "test[tt]=0\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ResponseID  Predicted Probability  True Label  Predicted Saved\n",
      "0  tensor(1)               0.807092        -1.0                1\n",
      "1  tensor(1)               0.233863        -2.0                0\n",
      "2  tensor(2)               0.556622        -2.0                1\n",
      "3  tensor(2)               0.466010        -1.0                0\n",
      "4  tensor(3)               0.486835        -1.0                1\n"
     ]
    }
   ],
   "source": [
    "# predict on test data set\n",
    "features = ['if_cross_by_rule', 'if_more_people',\n",
    "       'if_more_male', 'if_more_female', \n",
    "       'if_more_vulnerable', 'if_more_children', 'if_more_senior',\n",
    "       'if_more_criminal', 'if_more_homeless', 'if_more_profession',\n",
    "       'if_more_large', 'if_more_animal']\n",
    "\n",
    "ranknet_model = RankNetModel(features=features, model_path='ranknet_model.pth')\n",
    "\n",
    "ranknet_model.load_model()\n",
    "\n",
    "batch_size = 5\n",
    "predictions_list = []\n",
    "\n",
    "for start_idx in range(0, len(test), batch_size):\n",
    "    end_idx = start_idx + batch_size\n",
    "    batch = test.iloc[start_idx:end_idx]\n",
    "\n",
    "    predicted_batch = ranknet_model.predict(batch)\n",
    "    predictions_list.append(predicted_batch)\n",
    "\n",
    "predicted_df = pd.concat(predictions_list, ignore_index=True)\n",
    "\n",
    "print(predicted_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>Predicted Probability</th>\n",
       "      <th>True Label</th>\n",
       "      <th>Predicted Saved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>0.807092</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>0.233863</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(2)</td>\n",
       "      <td>0.556622</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(2)</td>\n",
       "      <td>0.466010</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(3)</td>\n",
       "      <td>0.486835</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensor(3)</td>\n",
       "      <td>0.497218</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tensor(4)</td>\n",
       "      <td>0.842381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tensor(4)</td>\n",
       "      <td>0.169891</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tensor(5)</td>\n",
       "      <td>0.809281</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensor(5)</td>\n",
       "      <td>0.223628</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tensor(6)</td>\n",
       "      <td>0.809281</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tensor(6)</td>\n",
       "      <td>0.809281</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tensor(7)</td>\n",
       "      <td>0.807092</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tensor(7)</td>\n",
       "      <td>0.556622</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tensor(8)</td>\n",
       "      <td>0.807092</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tensor(8)</td>\n",
       "      <td>0.556622</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tensor(9)</td>\n",
       "      <td>0.842381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tensor(9)</td>\n",
       "      <td>0.497218</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tensor(10)</td>\n",
       "      <td>0.842381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tensor(10)</td>\n",
       "      <td>0.497218</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tensor(11)</td>\n",
       "      <td>0.809281</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tensor(11)</td>\n",
       "      <td>0.809281</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tensor(12)</td>\n",
       "      <td>0.466010</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tensor(12)</td>\n",
       "      <td>0.233863</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tensor(13)</td>\n",
       "      <td>0.466010</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tensor(13)</td>\n",
       "      <td>0.233863</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tensor(14)</td>\n",
       "      <td>0.486835</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tensor(14)</td>\n",
       "      <td>0.169891</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tensor(15)</td>\n",
       "      <td>0.486835</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tensor(15)</td>\n",
       "      <td>0.169891</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tensor(16)</td>\n",
       "      <td>0.223628</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tensor(16)</td>\n",
       "      <td>0.223628</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tensor(17)</td>\n",
       "      <td>0.828245</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tensor(17)</td>\n",
       "      <td>0.727010</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tensor(18)</td>\n",
       "      <td>0.727010</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tensor(18)</td>\n",
       "      <td>0.828245</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tensor(19)</td>\n",
       "      <td>0.288993</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tensor(19)</td>\n",
       "      <td>0.199452</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tensor(20)</td>\n",
       "      <td>0.199452</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tensor(20)</td>\n",
       "      <td>0.288993</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ResponseID  Predicted Probability  True Label  Predicted Saved\n",
       "0    tensor(1)               0.807092        -1.0                1\n",
       "1    tensor(1)               0.233863        -2.0                0\n",
       "2    tensor(2)               0.556622        -2.0                1\n",
       "3    tensor(2)               0.466010        -1.0                0\n",
       "4    tensor(3)               0.486835        -1.0                1\n",
       "5    tensor(3)               0.497218        -2.0                1\n",
       "6    tensor(4)               0.842381        -1.0                1\n",
       "7    tensor(4)               0.169891        -2.0                0\n",
       "8    tensor(5)               0.809281        -1.0                1\n",
       "9    tensor(5)               0.223628        -2.0                0\n",
       "10   tensor(6)               0.809281        -1.0                1\n",
       "11   tensor(6)               0.809281        -2.0                0\n",
       "12   tensor(7)               0.807092        -1.0                1\n",
       "13   tensor(7)               0.556622        -2.0                0\n",
       "14   tensor(8)               0.807092        -1.0                1\n",
       "15   tensor(8)               0.556622        -2.0                1\n",
       "16   tensor(9)               0.842381        -1.0                1\n",
       "17   tensor(9)               0.497218        -2.0                0\n",
       "18  tensor(10)               0.842381        -1.0                1\n",
       "19  tensor(10)               0.497218        -2.0                1\n",
       "20  tensor(11)               0.809281        -1.0                1\n",
       "21  tensor(11)               0.809281        -2.0                0\n",
       "22  tensor(12)               0.466010        -1.0                1\n",
       "23  tensor(12)               0.233863        -2.0                1\n",
       "24  tensor(13)               0.466010        -1.0                1\n",
       "25  tensor(13)               0.233863        -2.0                1\n",
       "26  tensor(14)               0.486835        -1.0                1\n",
       "27  tensor(14)               0.169891        -2.0                0\n",
       "28  tensor(15)               0.486835        -1.0                1\n",
       "29  tensor(15)               0.169891        -2.0                0\n",
       "30  tensor(16)               0.223628        -1.0                1\n",
       "31  tensor(16)               0.223628        -2.0                0\n",
       "32  tensor(17)               0.828245        -1.0                1\n",
       "33  tensor(17)               0.727010        -2.0                1\n",
       "34  tensor(18)               0.727010        -1.0                1\n",
       "35  tensor(18)               0.828245        -2.0                1\n",
       "36  tensor(19)               0.288993        -1.0                1\n",
       "37  tensor(19)               0.199452        -2.0                1\n",
       "38  tensor(20)               0.199452        -1.0                1\n",
       "39  tensor(20)               0.288993        -2.0                1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
